{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d24a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasanna/coding/distilled-llm/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Cdatasets.tokenizer import MathTokenizer, load_tokenizer\n",
    "from scripts.model import GQATransformer\n",
    "from transformers import AutoTokenizer\n",
    "from Cdatasets.dataset import PretrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d15d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16652 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from Cdatasets.dataset import PretrainDataset\n",
    "from Cdatasets.tokenizer import load_tokenizer\n",
    "\n",
    "tok = load_tokenizer(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "ds = PretrainDataset(\n",
    "    data_dir=\"math-ai/AutoMathText\",   # HF dataset id, not a local path\n",
    "    tokenizer=tok,\n",
    "    block_size=256,\n",
    "    subset=\"arxiv-0.70-to-1.00\",       # optional\n",
    "    split=\"train\",\n",
    "    hf_cache_dir=\"/home/prasanna/.cache/huggingface/datasets\",\n",
    "    local_files_only=True,    \n",
    "    max_stream_rows=100000\n",
    "                      # use only cached files\n",
    ")\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "416be37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256]), torch.Size([256]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]['input_ids'].shape, ds[0]['targets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23c7e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "dataset = PretrainDataset(\n",
    "    data_dir=\"data/AutoMathText\",\n",
    "    tokenizer=tokenizer,\n",
    "    block_size=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8d4c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['url', 'title', 'abstract', 'text', 'meta'],\n",
      "    num_rows: 45169\n",
      "})\n",
      "rows: 45169\n",
      "columns: ['url', 'title', 'abstract', 'text', 'meta']\n",
      "\n",
      "row[0] keys: dict_keys(['url', 'title', 'abstract', 'text', 'meta'])\n",
      "title: Convergence directions of the randomized Gauss--Seidel method and its extension\n",
      "abstract: The randomized Gauss--Seidel method and its extension have attracted much attention recently and their convergence rates have been considered extensively. However, the convergence rates are usually de\n",
      "text: \\section{Introduction}\n",
      "Linear least squares problem is a ubiquitous problem arising frequently in data analysis and scientific computing. Specifically, given a data matrix $A\\in R^{m\\times n}$ and a data vector $b\\in R^{m}$, a linear least squares problem can be written as follows\n",
      "\\begin{equation}\n",
      "\\label{ls}\n",
      "\\min \\limits _{ x \\in R^{n}}\\|b-Ax\\|^2_{2}.\n",
      "\\end{equation}\n",
      "In the literature, several direct methods have been proposed for solving its normal equations $A^TAx=A^Tb$ through either the QR fa\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk(\"data/AutoMathText\")  # change path if needed\n",
    "print(ds)\n",
    "print(\"rows:\", len(ds))\n",
    "print(\"columns:\", ds.column_names)\n",
    "\n",
    "# first row raw\n",
    "row0 = ds[0]\n",
    "print(\"\\nrow[0] keys:\", row0.keys())\n",
    "print(\"title:\", (row0.get(\"title\") or \"\")[:120])\n",
    "print(\"abstract:\", (row0.get(\"abstract\") or \"\")[:200])\n",
    "print(\"text:\", (row0.get(\"text\") or \"\")[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c727a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence directions of the randomized Gauss--Seidel method and its extension\n",
      "\n",
      "The randomized Gauss--Seidel method and its extension have attracted much attention recently and their convergence rates have been considered extensively. However, the convergence rates are usually determined by upper bounds, which cannot fully reflect the actual convergence. In this paper, we make a detailed analysis of their convergence behaviors. The analysis shows that the larger the singular value of $A$ is, the faster the error decays in the corresponding singular vector space, and the convergence directions are mainly driven by the large singular values at the beginning, then gradually driven by the small singular values, and finally by the smallest nonzero singular value. These results explain the phenomenon found in the extensive numerical experiments appearing in the literature that these two methods seem to converge faster at the beginning. Numerical examples are provided to confirm the above fi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Cdatasets.dataset import PretrainDataset\n",
    "from Cdatasets.tokenizer import load_tokenizer\n",
    "\n",
    "tok = load_tokenizer(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "pds = PretrainDataset(\"data/AutoMathText\", tok, block_size=256)\n",
    "\n",
    "# pick raw HF row and format it the same way as training\n",
    "raw = ds[0]\n",
    "formatted = pds._format_row(raw)\n",
    "print(formatted[:1000])\n",
    "tok.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b47377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher: 60.90M parameters\n",
      "Student: 39.69M parameters\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = MathTokenizer()\n",
    "teacher = GQATransformer(\n",
    "    num_layers=tc.num_layers,\n",
    "    n_emb=tc.n_embd,\n",
    "    n_head=tc.n_head,\n",
    "    n_kv_head=tc.n_kv_head,\n",
    "    vocab_size=tc.vocab_size,\n",
    "    block_size=tc.block_size,\n",
    "    dropout=tc.dropout,\n",
    ")\n",
    "\n",
    "student = GQATransformer(\n",
    "    num_layers=sc.num_layers,\n",
    "    n_emb=sc.n_embd,\n",
    "    n_head=sc.n_head,\n",
    "    n_kv_head=sc.n_kv_head,\n",
    "    vocab_size=sc.vocab_size,\n",
    "    block_size=sc.block_size,\n",
    "    dropout=sc.dropout,\n",
    ")\n",
    "\n",
    "\n",
    "def count_parameters(model: GQATransformer) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Teacher: {count_parameters(teacher) / 1e6:.2f}M parameters\")\n",
    "print(f\"Student: {count_parameters(student) / 1e6:.2f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18557135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19d9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher: 121.74M parameters\n",
      "Student: 27.51M parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"Teacher: {count_parameters(teacher) / 1e6:.2f}M parameters\")\n",
    "print(f\"Student: {count_parameters(student) / 1e6:.2f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1458ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"deepseek-ai/deepseek-math-7b-base\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "text = r\"\"\"\n",
    "Solve: \\int_0^1 x^2 dx.\n",
    "Chain of thought: First compute the antiderivative...\n",
    "\"\"\"\n",
    "\n",
    "tokens = deepseek_tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Token IDs:\", tokens[\"input_ids\"][0][:20])\n",
    "print(\"Decoded:\", deepseek_tokenizer.decode(tokens[\"input_ids\"][0]))\n",
    "print(\"Vocab size:\", deepseek_tokenizer.vocab_size)\n",
    "print(\"Special tokens:\", deepseek_tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4267ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-Math-7B\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "text = r\"\"\"\n",
    "证明：若 a,b \\in \\mathbb{R}, 则 a^2 + b^2 \\ge 2ab.\n",
    "\"\"\"\n",
    "\n",
    "tokens = qwen_tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Token IDs:\", tokens[\"input_ids\"][0][:20])\n",
    "print(\"Decoded:\", qwen_tokenizer.decode(tokens[\"input_ids\"][0]))\n",
    "print(\"Vocab size:\", qwen_tokenizer.vocab_size)\n",
    "print(\"Special tokens:\", qwen_tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c138471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([    1,   960, 29871, 29896, 29906, 29941, 29946, 29945, 29985, 29906,\n",
      "          353,  1577, 29892, 10272,  4331, 29899,  1609, 29899, 10568, 29889])\n",
      "Decoded: <s> If 12345^2 = ?, compute step-by-step.\n",
      "Vocab size: 32000\n",
      "Special tokens: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llama_tokenizer = load_tokenizer(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "text = \"If 12345^2 = ?, compute step-by-step.\"\n",
    "\n",
    "tokens = llama_tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Token IDs:\", tokens[\"input_ids\"][0][:20])\n",
    "print(\"Decoded:\", llama_tokenizer.decode(tokens[\"input_ids\"][0]))\n",
    "print(\"Vocab size:\", llama_tokenizer.vocab_size)\n",
    "print(\"Special tokens:\", llama_tokenizer.special_tokens_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
